{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fast_inference_transformers_on_CPU.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "d688d08b86d1428f9254b959b0d39142": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9ff4c0e657eb4869a1e816d74d458b31",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f072f66be88d4edea7f826b1fea52625",
              "IPY_MODEL_75e0d0df297b41c982712d3384ad3026",
              "IPY_MODEL_8e5708a1901e49beac3fb74f0c572db4"
            ]
          }
        },
        "9ff4c0e657eb4869a1e816d74d458b31": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f072f66be88d4edea7f826b1fea52625": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_c1c920707b7b46ad8ad13fb0dbf4135f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2c15a661a1cd4224aa6564d40adf87df"
          }
        },
        "75e0d0df297b41c982712d3384ad3026": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_44eeb2b4309e4d61a49dd05885e27b11",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 494,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 494,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1e4ed81edd624c648d1c06c6e2134272"
          }
        },
        "8e5708a1901e49beac3fb74f0c572db4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_9818d9e1590e4343b7303e9b3089b34a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 494/494 [00:00&lt;00:00, 9.22kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_08760e7ecac7421ca94908d214178d1a"
          }
        },
        "c1c920707b7b46ad8ad13fb0dbf4135f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2c15a661a1cd4224aa6564d40adf87df": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "44eeb2b4309e4d61a49dd05885e27b11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1e4ed81edd624c648d1c06c6e2134272": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9818d9e1590e4343b7303e9b3089b34a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "08760e7ecac7421ca94908d214178d1a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "1e55594927c14fe6a1eb460034fd4a7e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_0c508ca924fc4f598a6f6137aa381129",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_4282939dfda44bfb93504ba68356d2ef",
              "IPY_MODEL_90a190d70c8541c4bd679c540568db62",
              "IPY_MODEL_ad46bec773f34971ba6fb39fdb7f9f7c"
            ]
          }
        },
        "0c508ca924fc4f598a6f6137aa381129": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4282939dfda44bfb93504ba68356d2ef": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_36abe8cb27f648cca5d1ea9a83ed081c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e24e4af42ce4406caca4e73533c3e9e6"
          }
        },
        "90a190d70c8541c4bd679c540568db62": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_9c9e260a7a694af7931369bf0c9b2145",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 862,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 862,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_85bf5e86dc154f578fef5cc8e564c208"
          }
        },
        "ad46bec773f34971ba6fb39fdb7f9f7c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_11d282a046dd409fa550994a5eb1b9a8",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 862/862 [00:00&lt;00:00, 18.9kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0e41f002dd524e3c979f4cd9285665ba"
          }
        },
        "36abe8cb27f648cca5d1ea9a83ed081c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e24e4af42ce4406caca4e73533c3e9e6": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9c9e260a7a694af7931369bf0c9b2145": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "85bf5e86dc154f578fef5cc8e564c208": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "11d282a046dd409fa550994a5eb1b9a8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0e41f002dd524e3c979f4cd9285665ba": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c54f3ff67f2546ab8238fded899924ce": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_5625e6f79e8c47cd881e833b71e6c014",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_346352fa85b447ef970ea9b3793d4e11",
              "IPY_MODEL_c3e6f5ad11d64ec787715a4549184959",
              "IPY_MODEL_97211b53c2f84aa0bd4026984010f033"
            ]
          }
        },
        "5625e6f79e8c47cd881e833b71e6c014": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "346352fa85b447ef970ea9b3793d4e11": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a62a25f533b8467989fda0b65a476aa1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_ae0502c90b634b96ab552396f9ce8a06"
          }
        },
        "c3e6f5ad11d64ec787715a4549184959": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_285f58eb40b746b991de75ca656365a1",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 209528,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 209528,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a7341db7724f41d1a37e2a8b253d3891"
          }
        },
        "97211b53c2f84aa0bd4026984010f033": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3f9d0bf143934e2098b9cc7a6f76e26e",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 205k/205k [00:00&lt;00:00, 2.11MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_acc7e51b97b4425f976c3edf255d7357"
          }
        },
        "a62a25f533b8467989fda0b65a476aa1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "ae0502c90b634b96ab552396f9ce8a06": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "285f58eb40b746b991de75ca656365a1": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a7341db7724f41d1a37e2a8b253d3891": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3f9d0bf143934e2098b9cc7a6f76e26e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "acc7e51b97b4425f976c3edf255d7357": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b3be362b07a94456bc27bbe43db80ae4": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_a5f91cf0a6f44e0b8a24e204d3170335",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_b32925b4ce2e4de0941f4abf15626df6",
              "IPY_MODEL_c01e0d7df5184711a27a681275200c57",
              "IPY_MODEL_8d74c887fc844194b29d6fae324a70a0"
            ]
          }
        },
        "a5f91cf0a6f44e0b8a24e204d3170335": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "b32925b4ce2e4de0941f4abf15626df6": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7f4211d36cfd4d1d824b4cda914fd98f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_07220d51a74648688888a2dbe0380f82"
          }
        },
        "c01e0d7df5184711a27a681275200c57": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_c85d841e183f4852bd5e21759c083ac2",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 112,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 112,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3aea8d9abc914b7a9cb271a310e88a33"
          }
        },
        "8d74c887fc844194b29d6fae324a70a0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_6d6fb024a7dd4d618874a44e031a7532",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 112/112 [00:00&lt;00:00, 1.97kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_3795f71d852e4107b081184e9fe21251"
          }
        },
        "7f4211d36cfd4d1d824b4cda914fd98f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "07220d51a74648688888a2dbe0380f82": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "c85d841e183f4852bd5e21759c083ac2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3aea8d9abc914b7a9cb271a310e88a33": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "6d6fb024a7dd4d618874a44e031a7532": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "3795f71d852e4107b081184e9fe21251": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "222288b79d464ae9aeb301b8a10ba665": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_1c6db545aba04a0d813d32906a72f0fd",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_e408e4dc8e1e4e448f9999f044b247ee",
              "IPY_MODEL_4f98c3c53266463c99f05b4a39312cda",
              "IPY_MODEL_4686a293864c42c4b27b4e348a6cea92"
            ]
          }
        },
        "1c6db545aba04a0d813d32906a72f0fd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e408e4dc8e1e4e448f9999f044b247ee": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_44e93820c3264528b4afe862a858a01f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": "Downloading: 100%",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_726d9170e81b491a85719517f08545d5"
          }
        },
        "4f98c3c53266463c99f05b4a39312cda": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_afb34d2ec42d4854b52e38546391d82d",
            "_dom_classes": [],
            "description": "",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 433422856,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 433422856,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_012e685c931d4e23bd0e09fcd2fe5297"
          }
        },
        "4686a293864c42c4b27b4e348a6cea92": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_7d765c4348aa46dab0fbc1d25c4d04b0",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 413M/413M [00:10&lt;00:00, 42.4MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a3ebc0adc6d943f5953b1afdf2cd0742"
          }
        },
        "44e93820c3264528b4afe862a858a01f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "726d9170e81b491a85719517f08545d5": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "afb34d2ec42d4854b52e38546391d82d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "012e685c931d4e23bd0e09fcd2fe5297": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "7d765c4348aa46dab0fbc1d25c4d04b0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a3ebc0adc6d943f5953b1afdf2cd0742": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hkUF5jx2Xxs"
      },
      "source": [
        "# Fast inference for Hugging Face tasks models on CPU (for example: QA model)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mDmIlOqh3Cyh"
      },
      "source": [
        "- **Author**: [Pierre Guillou](https://www.linkedin.com/in/pierreguillou/)\n",
        "- **Version & Date** : v1 (10/22/2021)\n",
        "- **Blog post**: [NLP nas empresas | Técnicas para acelerar modelos de Deep Learning para inferência em produção]()\n",
        "- **Other notebook** : [fast_inference_transformers_on_GPU.ipynb]()\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FREHU6cIboN8"
      },
      "source": [
        "## Notebook overview"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vre_6Zjfbq_s"
      },
      "source": [
        "### Objective\n",
        "The objective of this notebook is to help those who want to **accelerate inference time on CPU for tasks models of Hugging Face** (NER, QA, Classification...).\n",
        "\n",
        "### Method for inference\n",
        "\n",
        "source: https://discuss.pytorch.org/t/model-eval-vs-with-torch-no-grad/19615/2\n",
        "\n",
        "- `model.eval()` will notify all your layers that you are in eval mode, that way, batchnorm or dropout layers will work in eval mode instead of training mode.\n",
        "- `torch.no_grad()` impacts the autograd engine and deactivate it. It will reduce memory usage and speed up computations but you won’t be able to backprop (which you don’t want in an eval script).\n",
        "\n",
        "### References\n",
        "- post blog from HF and Microsoft: [Accelerate your NLP pipelines using Hugging Face Transformers and ONNX Runtime](https://medium.com/microsoftazure/accelerate-your-nlp-pipelines-using-hugging-face-transformers-and-onnx-runtime-2443578f4333) (19/05/2020)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DNmi0bXikgM3"
      },
      "source": [
        "## System overview"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "ov7T5Sk_pL_B",
        "outputId": "bebf6a56-de31-4852-aef5-807f08861093"
      },
      "source": [
        "import platform\n",
        "platform.platform()"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'Linux-5.4.104+-x86_64-with-Ubuntu-18.04-bionic'"
            ]
          },
          "metadata": {},
          "execution_count": 1
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "VvdQxXRHiXHL"
      },
      "source": [
        "### CPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3ViMgMkxklj7"
      },
      "source": [
        "from psutil import *"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dBjiK-_tkntn",
        "outputId": "b3e39cd1-85db-493b-8e65-f1cddebf4115"
      },
      "source": [
        "cpu_count(),cpu_stats()"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2,\n",
              " scpustats(ctx_switches=428611, interrupts=201695, soft_interrupts=213679, syscalls=0))"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SnzYmVM4kuwl",
        "outputId": "402a1d03-1424-485b-aa74-69bb5e01770c"
      },
      "source": [
        "!cat /proc/cpuinfo"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "processor\t: 0\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 79\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0x1\n",
            "cpu MHz\t\t: 2199.998\n",
            "cache size\t: 56320 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 2\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 1\n",
            "apicid\t\t: 0\n",
            "initial apicid\t: 0\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n",
            "bogomips\t: 4399.99\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n",
            "processor\t: 1\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 79\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.20GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0x1\n",
            "cpu MHz\t\t: 2199.998\n",
            "cache size\t: 56320 KB\n",
            "physical id\t: 0\n",
            "siblings\t: 2\n",
            "core id\t\t: 0\n",
            "cpu cores\t: 1\n",
            "apicid\t\t: 1\n",
            "initial apicid\t: 1\n",
            "fpu\t\t: yes\n",
            "fpu_exception\t: yes\n",
            "cpuid level\t: 13\n",
            "wp\t\t: yes\n",
            "flags\t\t: fpu vme de pse tsc msr pae mce cx8 apic sep mtrr pge mca cmov pat pse36 clflush mmx fxsr sse sse2 ss ht syscall nx pdpe1gb rdtscp lm constant_tsc rep_good nopl xtopology nonstop_tsc cpuid tsc_known_freq pni pclmulqdq ssse3 fma cx16 pcid sse4_1 sse4_2 x2apic movbe popcnt aes xsave avx f16c rdrand hypervisor lahf_lm abm 3dnowprefetch invpcid_single ssbd ibrs ibpb stibp fsgsbase tsc_adjust bmi1 hle avx2 smep bmi2 erms invpcid rtm rdseed adx smap xsaveopt arat md_clear arch_capabilities\n",
            "bugs\t\t: cpu_meltdown spectre_v1 spectre_v2 spec_store_bypass l1tf mds swapgs taa\n",
            "bogomips\t: 4399.99\n",
            "clflush size\t: 64\n",
            "cache_alignment\t: 64\n",
            "address sizes\t: 46 bits physical, 48 bits virtual\n",
            "power management:\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iU5N7WYs2Y9b",
        "outputId": "c41cb7f1-a2a7-4afb-8642-6fe59ecca321"
      },
      "source": [
        "!df -h"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Filesystem      Size  Used Avail Use% Mounted on\n",
            "overlay         108G   48G   60G  45% /\n",
            "tmpfs            64M     0   64M   0% /dev\n",
            "tmpfs           6.4G     0  6.4G   0% /sys/fs/cgroup\n",
            "shm             5.9G     0  5.9G   0% /dev/shm\n",
            "/dev/root       2.0G  1.2G  821M  59% /sbin/docker-init\n",
            "tmpfs           6.4G   28K  6.4G   1% /var/colab\n",
            "/dev/sda1        81G   51G   31G  63% /etc/hosts\n",
            "tmpfs           6.4G     0  6.4G   0% /proc/acpi\n",
            "tmpfs           6.4G     0  6.4G   0% /proc/scsi\n",
            "tmpfs           6.4G     0  6.4G   0% /sys/firmware\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r7DSRg45kzqp",
        "outputId": "9ed754ee-2b13-45c4-8f8f-fbda9d942f81"
      },
      "source": [
        "virtual_memory()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "svmem(total=13622198272, available=12758904832, percent=6.3, used=571662336, free=10892611584, active=1025048576, inactive=1454149632, buffers=82980864, cached=2074943488, shared=1175552, slab=188170240)"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xOuBqEynERFG"
      },
      "source": [
        "## Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "P_sWC1bkETZw"
      },
      "source": [
        "%%capture\n",
        "!pip install transformers"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OQxJyew3GOEg",
        "outputId": "4c97e338-83e8-4e84-ca09-639846080083"
      },
      "source": [
        "import transformers, torch, numpy as np\n",
        "\n",
        "print(\"transformers:\",transformers.__version__)\n",
        "print(\"torch:\",torch.__version__)\n",
        "print(\"numpy:\",np.__version__)"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "transformers: 4.11.3\n",
            "torch: 1.9.0+cu111\n",
            "numpy: 1.19.5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OFZpEH_scifg"
      },
      "source": [
        "from time import perf_counter\n",
        "def timer(f,*args):   \n",
        "    start = perf_counter()\n",
        "    f(*args)\n",
        "    return (1000 * (perf_counter() - start))"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "U2VWWKpbR5mL"
      },
      "source": [
        "## QA model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vDfR4S0DcNoi"
      },
      "source": [
        "Model at https://huggingface.co/pierreguillou/bert-base-cased-squad-v1.1-portuguese"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cBlOI89tR8Oq"
      },
      "source": [
        "model_checkpoint = \"pierreguillou/bert-base-cased-squad-v1.1-portuguese\"\n",
        "# model_checkpoint = \"pierreguillou/bert-large-cased-squad-v1.1-portuguese\""
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bclIDEVOSm-M"
      },
      "source": [
        "context = r\"\"\"\n",
        "A pandemia de COVID-19, também conhecida como pandemia de coronavírus, é uma pandemia em curso de COVID-19, \n",
        "uma doença respiratória aguda causada pelo coronavírus da síndrome respiratória aguda grave 2 (SARS-CoV-2). \n",
        "A doença foi identificada pela primeira vez em Wuhan, na província de Hubei, República Popular da China, \n",
        "em 1 de dezembro de 2019, mas o primeiro caso foi reportado em 31 de dezembro do mesmo ano. \n",
        "Acredita-se que o vírus tenha uma origem zoonótica, porque os primeiros casos confirmados \n",
        "tinham principalmente ligações ao Mercado Atacadista de Frutos do Mar de Huanan, que também vendia animais vivos. \n",
        "Em 11 de março de 2020, a Organização Mundial da Saúde declarou o surto uma pandemia. Até 8 de fevereiro de 2021, \n",
        "pelo menos 105 743 102 casos da doença foram confirmados em pelo menos 191 países e territórios, \n",
        "com cerca de 2 308 943 mortes e 58 851 440 pessoas curadas.\n",
        "\"\"\"\n",
        "\n",
        "question = \"Quando começou a pandemia de Covid-19 no mundo?\""
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QeiLPvAteK0q"
      },
      "source": [
        "## 1. Check the model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "itx8-vxHgrgI"
      },
      "source": [
        "Before evaluating its inference time, let's check that our QA model is working well."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dUixO7_ueq38"
      },
      "source": [
        "#### 1.1 Without pipeline"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 177,
          "referenced_widgets": [
            "d688d08b86d1428f9254b959b0d39142",
            "9ff4c0e657eb4869a1e816d74d458b31",
            "f072f66be88d4edea7f826b1fea52625",
            "75e0d0df297b41c982712d3384ad3026",
            "8e5708a1901e49beac3fb74f0c572db4",
            "c1c920707b7b46ad8ad13fb0dbf4135f",
            "2c15a661a1cd4224aa6564d40adf87df",
            "44eeb2b4309e4d61a49dd05885e27b11",
            "1e4ed81edd624c648d1c06c6e2134272",
            "9818d9e1590e4343b7303e9b3089b34a",
            "08760e7ecac7421ca94908d214178d1a",
            "1e55594927c14fe6a1eb460034fd4a7e",
            "0c508ca924fc4f598a6f6137aa381129",
            "4282939dfda44bfb93504ba68356d2ef",
            "90a190d70c8541c4bd679c540568db62",
            "ad46bec773f34971ba6fb39fdb7f9f7c",
            "36abe8cb27f648cca5d1ea9a83ed081c",
            "e24e4af42ce4406caca4e73533c3e9e6",
            "9c9e260a7a694af7931369bf0c9b2145",
            "85bf5e86dc154f578fef5cc8e564c208",
            "11d282a046dd409fa550994a5eb1b9a8",
            "0e41f002dd524e3c979f4cd9285665ba",
            "c54f3ff67f2546ab8238fded899924ce",
            "5625e6f79e8c47cd881e833b71e6c014",
            "346352fa85b447ef970ea9b3793d4e11",
            "c3e6f5ad11d64ec787715a4549184959",
            "97211b53c2f84aa0bd4026984010f033",
            "a62a25f533b8467989fda0b65a476aa1",
            "ae0502c90b634b96ab552396f9ce8a06",
            "285f58eb40b746b991de75ca656365a1",
            "a7341db7724f41d1a37e2a8b253d3891",
            "3f9d0bf143934e2098b9cc7a6f76e26e",
            "acc7e51b97b4425f976c3edf255d7357",
            "b3be362b07a94456bc27bbe43db80ae4",
            "a5f91cf0a6f44e0b8a24e204d3170335",
            "b32925b4ce2e4de0941f4abf15626df6",
            "c01e0d7df5184711a27a681275200c57",
            "8d74c887fc844194b29d6fae324a70a0",
            "7f4211d36cfd4d1d824b4cda914fd98f",
            "07220d51a74648688888a2dbe0380f82",
            "c85d841e183f4852bd5e21759c083ac2",
            "3aea8d9abc914b7a9cb271a310e88a33",
            "6d6fb024a7dd4d618874a44e031a7532",
            "3795f71d852e4107b081184e9fe21251",
            "222288b79d464ae9aeb301b8a10ba665",
            "1c6db545aba04a0d813d32906a72f0fd",
            "e408e4dc8e1e4e448f9999f044b247ee",
            "4f98c3c53266463c99f05b4a39312cda",
            "4686a293864c42c4b27b4e348a6cea92",
            "44e93820c3264528b4afe862a858a01f",
            "726d9170e81b491a85719517f08545d5",
            "afb34d2ec42d4854b52e38546391d82d",
            "012e685c931d4e23bd0e09fcd2fe5297",
            "7d765c4348aa46dab0fbc1d25c4d04b0",
            "a3ebc0adc6d943f5953b1afdf2cd0742"
          ]
        },
        "id": "v0Ewv1TleWqi",
        "outputId": "0719260b-015d-4af3-9bbb-9688b4a6546f"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)\n",
        "model.eval();"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d688d08b86d1428f9254b959b0d39142",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/494 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1e55594927c14fe6a1eb460034fd4a7e",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/862 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "c54f3ff67f2546ab8238fded899924ce",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/205k [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "b3be362b07a94456bc27bbe43db80ae4",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/112 [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "222288b79d464ae9aeb301b8a10ba665",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "Downloading:   0%|          | 0.00/413M [00:00<?, ?B/s]"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V3jrcdqmeWqj",
        "outputId": "237a489e-587c-4048-c122-8ec65695f586"
      },
      "source": [
        "# code source: https://huggingface.co/transformers/master/task_summary.html#extractive-question-answering\n",
        "\n",
        "# tokenize inputs\n",
        "inputs = tokenizer(question, context, add_special_tokens=True, return_tensors=\"pt\")\n",
        "\n",
        "# get outputs\n",
        "outputs = model(**inputs)\n",
        "answer_start_scores = outputs.start_logits\n",
        "answer_end_scores = outputs.end_logits\n",
        "\n",
        "# Get the most likely beginning of answer with the argmax of the score\n",
        "answer_start = torch.argmax(answer_start_scores)\n",
        "# Get the most likely end of answer with the argmax of the score\n",
        "answer_end = torch.argmax(answer_end_scores) + 1\n",
        "\n",
        "input_ids = inputs[\"input_ids\"].tolist()[0]\n",
        "answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n",
        "\n",
        "# print answer\n",
        "print(f\"Question: {question}\")\n",
        "print(f\"Answer: {answer}\")"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Quando começou a pandemia de Covid-19 no mundo?\n",
            "Answer: 1 de dezembro de 2019\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Wf-o7fLRewoY"
      },
      "source": [
        "That's the right answer!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XOINhKq2T3Bw"
      },
      "source": [
        "#### 1.2 With pipeline"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DFxfoEGXcoYj"
      },
      "source": [
        "We can use Pipeline, too."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5srv6sCpSeNt"
      },
      "source": [
        "from transformers import pipeline\n",
        "\n",
        "nlp = pipeline(\"question-answering\", model=model_checkpoint)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z0jMdQ92Tt_1",
        "outputId": "ca64d331-2cdd-4ecc-d645-a1042a130d60"
      },
      "source": [
        "# get result\n",
        "result = nlp(question, context)\n",
        "\n",
        "# print answer\n",
        "print(f\"Question: {question}\")\n",
        "print(f\"Answer: {result['answer']} (score: {round(result['score'], 4)})\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Quando começou a pandemia de Covid-19 no mundo?\n",
            "Answer: 1 de dezembro de 2019 (score: 0.713)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nMjpms2RfQ_9"
      },
      "source": [
        "That's the right answer!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PRV40jI3PkcM"
      },
      "source": [
        "## 2. Inference time | PyTorch model"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6KLKVAmpfe6v"
      },
      "source": [
        "### 2.1 PyTorch model (without pipeline)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sBTdifUAPuZf"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint)\n",
        "model.eval();"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HOdhaPFwl1Oe"
      },
      "source": [
        "#### 1. Tokenize the inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K1_5839CDbiD",
        "outputId": "82e8841a-7e58-4511-9bda-881508b43d46"
      },
      "source": [
        "num=100\n",
        "\n",
        "total = 0\n",
        "for i in range(num):\n",
        "  start = perf_counter()\n",
        "  inputs = tokenizer(question, context, add_special_tokens=True, return_tensors=\"pt\")\n",
        "  diff = perf_counter() - start\n",
        "  total += diff\n",
        "\n",
        "mean_tokenizer = round((total/num)*1000,2)\n",
        "print(f'average time: {mean_tokenizer} ms')"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average time: 0.7 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ulHNPdPQjhP"
      },
      "source": [
        "#### 2. Model on CPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CDnLS3HhA11U",
        "outputId": "88543a25-135a-4742-dd83-56d096a16369"
      },
      "source": [
        "# put model and inputs to cpu\n",
        "model = model.to('cpu')\n",
        "inputs = inputs.to('cpu')\n",
        "\n",
        "# get mean time\n",
        "with torch.no_grad():\n",
        "  mean_time_cpu = round(np.mean([timer(model,inputs.input_ids,inputs.token_type_ids,inputs.attention_mask) for _ in range(100)]),2)\n",
        "\n",
        "print(f'average time: {mean_time_cpu} ms')"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average time: 866.69 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S_nPfxys1qHa"
      },
      "source": [
        "Now, we can evaluate the time to get the answer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uesjhmxfnBbF"
      },
      "source": [
        "# get outputs\n",
        "with torch.no_grad():\n",
        "  outputs = model(**inputs)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eSHZvVABm5Iq",
        "outputId": "ed732bef-7d64-449b-e770-0166253bf5d5"
      },
      "source": [
        "num = 100\n",
        "\n",
        "total = 0\n",
        "for i in range(num):\n",
        "  start = perf_counter()\n",
        "  answer_start_scores = outputs.start_logits\n",
        "  answer_end_scores = outputs.end_logits\n",
        "\n",
        "  # Get the most likely beginning of answer with the argmax of the score\n",
        "  answer_start = torch.argmax(answer_start_scores)\n",
        "  # Get the most likely end of answer with the argmax of the score\n",
        "  answer_end = torch.argmax(answer_end_scores) + 1\n",
        "\n",
        "  input_ids = inputs[\"input_ids\"].tolist()[0]\n",
        "  answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n",
        "  diff = perf_counter() - start\n",
        "  total += diff\n",
        "\n",
        "mean_time_cpu_answer = round((total/num)*1000,2)\n",
        "print(f'average time: {mean_time_cpu_answer} ms')"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average time: 1.04 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "E9elF7xIVR7l"
      },
      "source": [
        "Then, we have the total time when the model is on the CPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiwJwBQEVaOi",
        "outputId": "dc5e5e8a-1637-437c-cce6-f8eb8e23dba6"
      },
      "source": [
        "total_cpu = round(mean_tokenizer + mean_time_cpu + mean_time_cpu_answer,2)\n",
        "print(f'time: {total_cpu} ms')"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 868.43 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "huZuti5kdqmb"
      },
      "source": [
        "### 2.2 PyTorch model (with pipeline)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PGi0rLL3XGLu"
      },
      "source": [
        "We can use Pipeline, too."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JUaBkiE7XGME"
      },
      "source": [
        "from transformers import pipeline"
      ],
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "H5uzUO81W-2P"
      },
      "source": [
        "#### 1. Model on CPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tjLIIq9Y_yH"
      },
      "source": [
        "We have the total time when the model is on the CPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8rTWTujiW-2P",
        "outputId": "9d44bd05-2318-4759-e260-8a61ff5c4ae5"
      },
      "source": [
        "# put model and inputs to cpu\n",
        "nlp = pipeline(\"question-answering\", model=model_checkpoint, use_fast=True, device=-1)\n",
        "\n",
        "# get mean time\n",
        "with torch.no_grad():\n",
        "  pipeline_mean_time_cpu = round(np.mean([timer(nlp,question,context) for _ in range(100)]),2)\n",
        "\n",
        "print(f'average time: {pipeline_mean_time_cpu} ms')"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average time: 873.3 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PIozp6wuZxWC"
      },
      "source": [
        "### 2.3 Results with PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "q1F3FQUsMLAR",
        "outputId": "89d2f8e0-0eb7-448b-ab6d-4ca784ba8b1d"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "raw_data = {\n",
        "            'Latency on CPU (ms)': [mean_time_cpu, pipeline_mean_time_cpu],\n",
        "            }\n",
        "\n",
        "df = pd.DataFrame(raw_data,\n",
        "                  index=pd.Index(['Without pipeline', 'With pipeline']),\n",
        "                  columns=pd.Index(['Latency on CPU (ms)']))\n",
        "\n",
        "df"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Latency on CPU (ms)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>Without pipeline</th>\n",
              "      <td>866.69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>With pipeline</th>\n",
              "      <td>873.30</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                  Latency on CPU (ms)\n",
              "Without pipeline               866.69\n",
              "With pipeline                  873.30"
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "QfTf24EPMLAR",
        "outputId": "32805539-164c-44e5-c918-b880554b2477"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "labels = ['CPU']\n",
        "data = [mean_time_cpu, pipeline_mean_time_cpu]\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "\n",
        "X = np.arange(1)\n",
        "ax.bar(X - 0.1, data[0], color = 'r', width = 0.2, label='Without pipeline')\n",
        "ax.bar(X + 0.1, data[1], color = 'g', width = 0.2, label='With pipeline')\n",
        "\n",
        "# axes and title\n",
        "x = np.arange(len(labels))  # the label locations\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(labels)\n",
        "ax.set_ylabel('Latency (ms)')\n",
        "ax.set_title('Inference latency of PyTorch model (CPU)')\n",
        "\n",
        "leg = ax.legend();"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAeYAAAFPCAYAAACYgG3pAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nO3debxVdb3/8ddHRhXEiSxEwXDAAUEFx6uSkKiZVo5oSl6V2/2lKc7d600sLc1yqMy5xNScKiPTnDUTUyARAlLBiUGUWSYH4Pv7Y61z3BzPsMGzz1l4Xs/HYz/OXuv7XWt99j7D+3zXWnutSCkhSZKKYZ3mLkCSJH3MYJYkqUAMZkmSCsRgliSpQAxmSZIKxGCWJKlADGZVTERsFhF/i4hFEfGz5q5nTUTErRFxSXPXUSkR8d8R8U5ELI6ITZq7nnJFRIqIrQtQR/+ImF5m3+ERcXs97e0iYlJEfKHxKqy3ntMj4vKm2JZWj8Gs1RIRb0TEwDK7DwXmABuklM6uYFmFEBFPRcQpzV1HuSKiDXAlcGBKqUNKaW6N9u55AC7OH29ExAVlrHdxyWNlRCwrmT6+Uq/nM2Ao8LeU0ttVMyJi94h4MCIWRMS8iHghIk7K2/rn7+/i/J/fl2u0feIfhho/ozcBx0fE55rgtWk1GMyqpG7ApLQGV7GJiNYVqEer2gxoD0xsoN+GKaUOwGDg+xFxUH2d85DvkC/zFvDVknl3lFNYC/3+fxv4bdVEROwFPAE8DWwNbAL8N3BwyTIz8/d5A+B84KaI2KGcjaWU3gceAk5slOrVaAxmrbGI+FZE/D0ifhoR8yPi9Yg4OG+7FRgCnJf/Rz8wItaJiAsiYmpEzI2IeyJi47x/1ejs5Ih4i+wPEhHxnxExOV//wxHRrWT7KSK+HRGv5iOKayMiStpPzZddlO8i3DWf3yUifh8Rs/Oav1vm690oIh7Il5ufP++at10K7Av8Mn+9v8zn94yIR/PRzssRcXTJ+m7Na/5LXuPzEdGjpH3HkmXfiYj/iYjPR8TS0t3OEbFrXlObWmpuFxFXR8TM/HF1Pm9b4OW824KIeKKh159Seo4sxHfK617l8EREjIyIYfW8f7XWkrf1j4jpEXF+RMwCfhMRrfLXPDV/f8ZGxBYlqxxY1/e+xnaHR8S9EXF7vp4JEbFtRHwvIt6NiGkRcWBJ/y75a5kXEVMi4tSStnXz79v8iJgE9KuxrTX92doS+CLwfMnsK4ARKaXLU0pzUmZsSunomsvnbfcD84Gygjn3FPCV1eivppBS8uGj7AfwBjAwf/4t4CPgVKAV2X/zM4HI228FLilZ9gzgH0BXoB1wA/C7vK07kIDbgPWBdYHDgSnA9kBr4EJgVMn6EvAAsCGwJTAbOChvOwqYQfaHM8hGHN3I/hkdC3wfaEv2x/A1YFAdr7f6NZCNWI4A1gM6AvcC95f0fQo4pWR6fWAacFJe/y5ku/Z3KFn3XGD3vP0O4K68rSPwNnA22ai2I7BH3vYg8N8l27kK+EUd9f8gf88/B3QGRgE/rPGet65j2er2/D3cB1gKDMhrngmsk/fdNG/brJ6fl/pq6Q8sBy7PfzbWBc4FJgDb5dvvDWzS0Pe+ltcxHHgfGJS/ltuA14H/BdqQ/fy+XtL/b8Cv8ve9T77uA/K2y4BngI2BLYB/AdPztnp/tvI6bq+jxq8AE0um1wNWAF+q53exf41tf53s93G70rYayzzFqj+juwLzmvvvio8a36fmLsDH2vXgk8E8paRtvfwP5ufz6VtZNZgnAwNKpr+Q/yFpzcch8MWS9oeAk0um1yH7498tn07Af5S03wNckD9/GDijlvr3AN6qMe97wG/qeL2rvIYabX2A+SXTNf/oHQM8U2OZG4CLStZ9c0nbIcC/8+eDgRfr2O4xwLP581bALGD3OvpOBQ4pmR4EvJE/r3rPGwrmBWQjscnAd2t8P7+cPz8NeLCBn5f6aukPfAi0L2l/GTi8jtrq/N7X0nc48GjJ9FeBxUCrfLpjvr4NycJ2BdCxpP+PgVvz569R8g8A2XHhqnCs92eL+oP5eOAfJdOb5zX1rOd3sT+wMv/+zAPGAceWtJUTzNsAK+raho/mebTE4zhqXLOqnqSUluZ7EzvU0bcb8MeIWFkybwXZsc4q02r0v6bGLtMg+6P1Zs3tk4V21ba3IAuC2mroEhELSua1IhsF1Ssi1iMbnR4EbJTP7hgRrVJKK+rY1h41ttWakuOIa1A/wJ+A6yNiK7LR0cKU0gt19O3Cx+8V+fMudfSty6YppeW1zB8BfBN4NP96TQPraaiW2Sk77lmlvvcA6n7vavNOyfNlwJyS79my/GuHvJ55KaVFNersW/IaptVoq7LGP1tk//h0rDG9kuyf13/Xs9zMlFLXWuYvJ9sbUFMbsn+Gq3QEFpZRn5qQwaymNA34z5TSszUbIqJ7/jTV6H9pKvOEoVq21aOO+a+nlLZZg3WeTRaEe6SUZkVEH+BFsn8WYNXaq7b1dErpy2uwrWnAsbU1pJTej4h7yMKwJ6sGfU0zyQKj6gSvLfN5jeF24F8R0ZvscMP9DfRvqJba3r8eZLuLm8pMYOOI6FgSzluSHRaB7PDCFqz6Gqp8mp+t8cBWEdE6pbQ8/yf3ObJDJ0+uwfreAjaNiA4ppcUA+TH4bqz6z8T2wEtrsH5VkCd/qSldD1xadQJXRHSOiMMb6P+9iNgx798pIo4qc1s3A+dExG6R2Trf7gvAovwko3XzE4x2ioh+DawPstHFMrKTpTYGLqrR/g7ZccUqDwDbRsQJEdEmf/SLiO3L2NYDwBci4sz8pKmOEbFHSfttZIcSDqP+YP4dcGH+Xm9Kdvyzzs/Sro6U0nRgdL7936eUljWwyOrWcjPww4jYJv8e7hwV/qx1Smka2bHvH0dE+4jYGTi5pM57yH4mN4rsxL/TSxZf45+t/L2cQnbsvsp5wLci4tyq1x0RvSPirjLW9xbZiWSXR0SH/CS7c8lGy/8o6bo/2SEjFYjBrKZ0DTASeCQiFpH9gdijrs4ppT+SnQx0V0S8RzZyOriu/jWWvRe4FLgTWEQ2mts43315KNnx4dfJTsa6GehUxmqvJjspaU5e+19reX1H5mfs/jwfcR1INvKdSbbrterkpobqXwR8mex46CzgVeBLJe3Pku3q/GdK6c1aV5K5BBhDNiKbAPwzn9dYRgC9qP+fgzWt5UqyIHwEeA+4hez9r7TBZMfXZwJ/JDsn4LG87WKyEefreV3Vr/tT/mxBdv7BCSXrGwUckD9ei4h5wI1kJ/+V4xiyE+2mkI34BwBfqTpcEBHtyc5rGFHm+tREqs6elbSWiewjTnemlG5uxhr2IxtNdkv+MflU8lHti2QnSL7dUP9G2N7pwBYppfMqvS2tHoNZWgvlu0cfJfvDuqih/hWqoQ1wF/BSSukHzVGD9FnkrmxpLRMRI4DHgDObMZS3J/uYzhfIdvFLaiSOmCVJKhBHzJIkFYjBLElSgazVFxjZdNNNU/fu3Zu7DEmSVsvYsWPnpJQ619a2Vgdz9+7dGTNmTHOXIUnSaomIOq8/4K5sSZIKxGCWJKlADGZJkgpkrT7GLEmfJR999BHTp0/n/fffb7iz1grt27ena9eutGlT2104a2cwS1JBTJ8+nY4dO9K9e3fye5trLZZSYu7cuUyfPp2tttqq7OXclS1JBfH++++zySabGMqfERHBJptsstp7QAxmSSoQQ/mzZU2+nwazJAmAYcOGcfXVH9+TZNCgQZxyyinV02effTZXXnklI0eO5LLLLgPg/vvvZ9KkSdV9+vfv32jXl/jRj3602st8//vf57HHHmu4Yy1uvfVWTjvtNACuv/56brvttjVaz6dlMEtSUUU07qMB++yzD6NGjQJg5cqVzJkzh4kTJ1a3jxo1ir333pvDDjuMCy64APhkMDemNQnmH/zgBwwcOPBTb/vb3/42J5544qdez5owmCVJAOy9994899xzAEycOJGddtqJjh07Mn/+fD744AMmT57MrrvuWj2yHDVqFCNHjuTcc8+lT58+TJ06FYB7772X3XffnW233ZZnnnkGyI6fn3TSSfTq1YtddtmFJ598Elh1lApw6KGH8tRTT3HBBRewbNky+vTpw/HHH/+JWjt06MCwYcPYcccdGTBgALNnzwbgW9/6Fvfddx+QXR3yvPPOo1evXuy+++5MmTIFgNmzZ3PEEUfQr18/+vXrx7PPPvuJ9Q8fPpyf/vSnQLYX4Pzzz//Ea1qxYgXnnnsu/fr1Y+edd+aGG2749N8EDGZJUq5Lly60bt2at956i1GjRrHXXnuxxx578NxzzzFmzBh69epF27Ztq/tXjZ6vuOIKxo0bR48ePQBYvnw5L7zwAldffTUXX3wxANdeey0RwYQJE/jd737HkCFD6j0p6rLLLmPddddl3Lhx3HHHHZ9oX7JkCX379mXixInsv//+1dupqVOnTkyYMIHTTjuNM888E4AzzjiDYcOGMXr0aH7/+9+vsru+LrW9pltuuYVOnToxevRoRo8ezU033cTrr7/e4Loa4selJEnV9t57b0aNGsWoUaM466yzmDFjBqNGjaJTp07ss88+Za3jG9/4BgC77bYbb7zxBgB///vfOf300wHo2bMn3bp145VXXlnjOtdZZx2OOeYYAL75zW9Wb7OmwYMHV38dNmwYAI899tgqu9/fe+89Fi9evNqv6ZFHHmH8+PHVI/SFCxfy6quvrtZHo2pjMEuqVVzs2cFN7aEDH2LJzCXV030bef1jZjZ8UlbXHbty/6P3M+6f43h/4/dp17odD//oYTp07MChxxzKmJljeH3+67y75F3GzBzDnKVzmDpvavW6F324iKnvTaXdzHYsmLeApR8sZczMMSx4fwEvz3mZDWZuAMDiDxcz8d2JvLXoLWYtmlW9/LsL3+XlOS/TYWYHVqaV9dY8ZuYYWrduzfR3prNs+bJP1PPhig+Z8O4E5rWfx/KPlrMircjmL/+Qa/9wLe3at6te17/f+/cqr2vmopmsu3Jdxswcw6IPF9GuXda3VatWLF++HMg+p/yLX/yCQYMGrdk3pA7uypYkVdu5784889gzbLDhBrRq1YpOG3Vi8XuLGT92PL379v5E//U7rM+SJUtqWdOq+uzeh7/+8a8AvDn1TWbNmEW3Ht3oskUXXpn4CitXrmTWjFlMGvfxSLZ1m9Ys/2h5retbuXIlT/zlCQAe/uPD9Nm9T639Hh35KACPjHyEXrv1AmDP/ffknt/cU93n5X+93GD9tRk0aBDXXXcdH330EQCvvPJKWe9FQxwxl/Lzg9LHhjd3AWoOW2+/NQvnLeSgrx1UPa9Hzx4sXbKUDTfe8BP9Dzz8QC4991LuvuVuLr/x8jrXe+SQI7nse5dx7IBjadWqFRdddRFt27Wld7/edNmyC0f3P5qtttmK7XptV73M14//OoMHDma7XttxyS8vWWV96663LhNfnMgt19zCxptszI+ur/0M7kULFzF44GDatG3DpddeCsA5PzyHy//ncgYPHMyK5SvYZY9d+N7l31ut9wnglFNO4Y033mDXXXclpUTnzp25//77V3s9NUVK6VOvpLn07ds3Ner9mA1mqVoMb+4KWp6HDnyITbtt2txlrBX222Y//vbq3+rtc9geh3HbQ7fV+g/F6urbZc0PLEyePJntt99+lXkRMTalVOtK3ZUtSVKBuCtbkrTWaWi0DDDy+ZFNUEnjc8QsSVKBGMySJBWIwSxJUoEYzJIkFYjBLEkC4MqLruTOm+6snj79uNO55JyPPz981cVXcccNd/D0I09z6y9vBeCpvz7Fa6+8Vt3nv478Lya9tOZ3mzrjhDNYtHDRGi07/MzhPP7A4wBccs4lq9S1NvGsbEkqqH439WvU9Y0+dXS97b379eaxPz8Gp2ZX1lowbwFLFn18JasJYyYwbPgweu3Wi/0P3B/IgnnfgfvyxW2/2Cg1XvPbaxplPRf+9MJGWU9zcMQsSQKyy3GOHzsegNdefo0e2/VgvQ7r8d6C9/jwgw95fcrr9OzVkz/f/Wd+8r8/4aXRL/HMo8/w80t+znFfPo7pb0wH4PEHHmfIV4ZwxH8cwYvPv/iJ7YwdNZah3xjKmSecyRH7HsGPz/8xK1euBLKLgiyYt4CZ02Zy5H5HcuFpF3LU/kdx/qnn8/6y7G5Uk8dPZugRQznhoBM4/bjTmfPOnE9so3Tkvt82+/Gry37FcQOP46RDT2Lu7LkAzJ87n/NOPY8TDzmREw85kZdGv9T4b+oaMJglSQB0/nxnWrduzawZsxg/Zjy9duvFjrvsyISxE5g8fjJb99yaNm3bVPfv3a83+355X7574Xe589E76dq9K5DdInHEX0Zw1sVncdOVN9W6rYnjJnLOJedwz1P3MP3N6Tz54JOf6PPm1Dc5ashR3Pv0vazfcX3uHXEvyz9azhUXXsHlN17Ob//6W756zFf51eW/qvd1LVu6jJ123Yk7H7uTXfbchfvvyC6b+bPv/4zjTj2O2x68jZ/c9JNVdts3J3dlS5Kq9erbi/FjxjN+zHiOG3ocs2fNZvyY8XTYoAM799u5rHUccMgBAPTcuSdvT3+71j479tmRrt2yIB/0tUGMe2EcAw4dsEqfzbpsRu9+2Y0zDv7Gwdz967vZq/9evPbya3zn2O8A2S73TT9X/2VM27Rtw75f3jerqVdPXnjmBQBeeOaFVY5DL1m8hKVLlrLe+uuV9TorxWCWJFXr3bc348eMZ8q/p9CjZw8267IZt99we/VtH8tRNapu1aoVK5avqL1TjVsTRC33Kqg5LyIgwRe3/SK//vOvy6oFoHXr1tXrKr1t48qVK/nNn3+zyu0fi8Bd2ZKkapW67WNNk8ZNYsZbM1i5ciWPjny01ts2Vu1SB3j4/ofp3a833Xp0Y/68+dXzl3+0nKkvT13t7UPj3f6xsRnMkqRqVbd97LVrr+p5PXr2oEPHDnXe9vH2627n+AOPrz75qxw79N6BK/73Co7a/yi6bNGF/gf3/0Sfbj26ce+Iezlq/6N4b+F7HDnkSNq0bcNlN1zGL3/0S44beBzHHXhcdUivrnN+eA6TXprE4IGDObr/0fzht39Yo/U0Nm/7WMrbPkrVvO1j02spt30cO2ost19/O1fddlWdfWZOm8mwIcO4+4m7m7Cyun1mbvsYEcMiYmJE/CsifhcR7SNiq4h4PiKmRMTdEdE279sun56St3evZG2SJBVRxYI5IjYHvgv0TSntBLQCjgUuB65KKW0NzAdOzhc5GZifz78q7ydJ+ozZbe/d6h0tA3TZokthRstNrdLHmFsD60ZEa2A94G3gAOC+vH0E8LX8+eH5NHn7gKjtND1Jkj7DKhbMKaUZwE+Bt8gCeSEwFliQUlqed5sObJ4/3xyYli+7PO+/SaXqk6SiWclKWHtP+1Et1uQ8rkruyt6IbBS8FdAFWB84qBHWOzQixkTEmNmzZ3/a1UlSYUx5bwrLlyw3nD8jUkrMnTuX9u3br9ZylbzAyEDg9ZTSbICI+AOwD7BhRLTOR8VdgRl5/xnAFsD0fNd3J2BuzZWmlG4EboTsrOwK1i9JTWr4P4cznOFsvcHWrOOnWQtl8sLJa7Rc+/bt6dq162otU8lgfgvYMyLWA5YBA4AxwJPAkcBdwBDgT3n/kfn0c3n7E2lt/iyXJK2m+R/O54x/nNHcZagW6aKmi6NKHmN+nuwkrn8CE/Jt3QicD5wVEVPIjiHfki9yC7BJPv8s4IJK1SZJUlFV9FrZKaWLgItqzH4N2L2Wvu8DR1WyHkmSis6DGJIkFYjBLElSgRjMkiQViMEsSVKBGMySJBWIwSxJUoEYzJIkFYjBLElSgRjMkiQViMEsSVKBGMySJBWIwSxJUoEYzJIkFYjBLElSgRjMkiQViMEsSVKBGMySJBWIwSxJUoEYzJIkFYjBLElSgRjMkiQViMEsSVKBGMySJBWIwSxJUoEYzJIkFYjBLElSgRjMkiQViMEsSVKBGMySJBWIwSxJUoEYzJIkFYjBLElSgRjMkiQViMEsSVKBGMySJBWIwSxJUoEYzJIkFYjBLElSgRjMkiQViMEsSVKBGMySJBWIwSxJUoEYzJIkFYjBLElSgRjMkiQViMEsSVKBGMySJBWIwSxJUoEYzJIkFYjBLElSgRjMkiQViMEsSVKBGMySJBWIwSxJUoFUNJgjYsOIuC8i/h0RkyNir4jYOCIejYhX868b5X0jIn4eEVMiYnxE7FrJ2iRJKqJKj5ivAf6aUuoJ9AYmAxcAj6eUtgEez6cBDga2yR9DgesqXJskSYVTsWCOiE7AfsAtACmlD1NKC4DDgRF5txHA1/LnhwO3pcw/gA0j4guVqk+SpCKq5Ih5K2A28JuIeDEibo6I9YHNUkpv531mAZvlzzcHppUsPz2ft4qIGBoRYyJizOzZsytYviRJTa+Swdwa2BW4LqW0C7CEj3dbA5BSSkBanZWmlG5MKfVNKfXt3LlzoxUrSVIRVDKYpwPTU0rP59P3kQX1O1W7qPOv7+btM4AtSpbvms+TJKnFqFgwp5RmAdMiYrt81gBgEjASGJLPGwL8KX8+EjgxPzt7T2BhyS5vSZJahNYVXv/pwB0R0RZ4DTiJ7J+BeyLiZOBN4Oi874PAIcAUYGneV5KkFqWiwZxSGgf0raVpQC19E/CdStYjSVLReeUvSZIKxGCWJKlADGZJkgrEYJYkqUAMZkmSCsRgliSpQAxmSZIKxGCWJKlAGrzASESsQ3Yv5S7AMuBfKaV3619KkiStiTqDOSJ6AOcDA4FXyW7h2B7YNiKWAjcAI1JKK5uiUEmSWoL6RsyXANcB/5VfLrNaRHwOOA44ARhRufIkSWpZ6gzmlNLgetreBa6uSEWSJLVgDZ78FRFHRUTH/Pn/RcQfImLXypcmSVLLU85Z2f+XUloUEf9BdleoW8h2cUuSpEZWTjCvyL9+BbgxpfQXoG3lSpIkqeUqJ5hnRMQNwDHAgxHRrszlJEnSaionYI8GHgYGpZQWABsD51a0KkmSWqgGLzCSUloaEU8CW5Sc9DWnsmVJktQylXPlrx8C3wKmAlWfZ07AAZUrS5KklqnBYCbbld0jpfRhpYuRJKmlK+cY87+ADStdiCRJKm/E/GPgxYj4F/BB1cyU0mEVq0qSpBaqnGAeAVwOTAC8YYUkSRVUTjAvTSn9vOKVSJKksoL5mYj4MTCSVXdl/7NiVUmS1EKVE8y75F/3LJnnx6UkSaqAci4w8qWmKESSJNXzcamI+GZE1NfeI7/jlCRJaiT1jZg3IfuY1FhgLDAbaA9sDexPdlnOCypeoSRJLUidwZxSuiYifkl2LHkfYGdgGTAZOCGl9FbTlChJUstR7zHmlNIK4NH8IUmSKsz7KkuSVCAGsyRJBdJgMEdEq6YoRJIklTdifjUiroiIHSpejSRJLVw5wdwbeAW4OSL+ERFDI2KDCtclSVKL1GAwp5QWpZRuSintDZwPXAS8HREjImLrilcoSVILUtYx5og4LCL+CFwN/Az4IvBn4MEK1ydJUotSzk0sXgWeBK5IKY0qmX9fROxXmbIkSWqZygnmnVNKi2trSCl9t5HrkSSpRSvn5K9rI2LDqomI2Cgifl3BmiRJarHKCeadU0oLqiZSSvP5+B7NkiSpEZUTzOtExEZVExGxMeXtApckSaupnID9GfBcRNwLBHAkcGlFq5IkqYVqMJhTSrfl92T+Uj7rGymlSZUtS5KklqncXdL/BuZX9Y+ILb0fsyRJja/BYI6I08mu9vUOsIJsd3YCdq5saZIktTzljJjPALZLKc2tdDGSJLV05ZyVPQ1YWOlCJElSeSPm14CnIuIvwAdVM1NKV1asKkmSWqhygvmt/NE2f0iSpAop5+NSFwNExHoppaWVL0mSpJarnNs+7hURk8g+MkVE9I6IX1W8MkmSWqByTv66GhgEzAVIKb0EeLtHSZIqoJxgJqU0rcasFeVuICJaRcSLEfFAPr1VRDwfEVMi4u6IaJvPb5dPT8nbu5e7DUmSPivK+rhUROwNpIhoExHnAJNXYxtn1Oh/OXBVSmlrsquJnZzPPxmYn8+/Ku8nSVKLUk4wfxv4DrA5MAPoA/y/clYeEV2BrwA359MBHADcl3cZAXwtf354Pk3ePiDvL0lSi1HOx6W2SykdXzojIvYBni1j2auB84CO+fQmwIKU0vJ8ejpZ4JN/nQaQUloeEQvz/nNqbHsoMBRgyy23LKMESZLWHuWMmH9R5rxVRMShwLsppbGrXVU9Uko3ppT6ppT6du7cuTFXLUlSs6tzxBwRewF7A50j4qySpg2AVmWsex/gsIg4BGifL3cNsGFEtM5HzV3Jdo+Tf90CmB4RrYFO5GeCS5LUUtQ3Ym4LdCAL744lj/eAIxtacUrpeymlriml7sCxwBP5LvEnS5YfAvwpfz4ynyZvfyKllFbr1UiStJarc8ScUnoaeDoibk0pvdmI2zwfuCsiLgFeBG7J598C/DYipgDzyMJckqQWpZyTv5ZGxBXAjmS7pAFIKR1Q7kZSSk8BT+XPXwN2r6XP+8BR5a5TkqTPonJO/rqD7HKcWwEXA28AoytYkyRJLVY5wbxJSukW4KOU0tMppf8k+yyyJElqZOXsyv4o//p2RHwFmAlsXLmSJElqucoJ5ksiohNwNtnnlzcAzqxoVZIktVDl3I/5gfzpQuBLABFhMEuSVAFl3V2qFmc13EWSJK2uNQ1mby4hSVIFrGkwe0UuSZIqoL5rZS+i9gAOYN2KVSRJUgtW3yU5O9bVJkmSKmNNd2VLkqQKMJglSSoQg1mSpAIxmCVJKhCDWZKkAjGYJUkqEINZkqQCMZglSSoQg1mSpAIxmCVJKhCDWZKkAjGYJUkqEINZkqQCMZglSSoQg1mSpAIxmCVJKhCDWZKkAjGYJUkqEINZkqQCMZglSSoQg1mSpAIxmCVJKhCDWZKkAjGYJUkqEINZkqQCMZglSSoQg1mSpAIxmCVJKhCDWZKkAjGYJUkqEINZkqQCMZglSSoQg1mSpAIxmCVJKhCDWZKkAjGYJUkqEINZkqQCMZglSSoQg1mSpAIxmCVJKhCDWQoO79QAAATZSURBVJKkAjGYJUkqEINZkqQCqVgwR8QWEfFkREyKiIkRcUY+f+OIeDQiXs2/bpTPj4j4eURMiYjxEbFrpWqTJKmoKjliXg6cnVLaAdgT+E5E7ABcADyeUtoGeDyfBjgY2CZ/DAWuq2BtkiQVUsWCOaX0dkrpn/nzRcBkYHPgcGBE3m0E8LX8+eHAbSnzD2DDiPhCpeqTJKmImuQYc0R0B3YBngc2Sym9nTfNAjbLn28OTCtZbHo+T5KkFqPiwRwRHYDfA2emlN4rbUspJSCt5vqGRsSYiBgze/bsRqxUkqTmV9Fgjog2ZKF8R0rpD/nsd6p2Uedf383nzwC2KFm8az5vFSmlG1NKfVNKfTt37ly54iVJagaVPCs7gFuAySmlK0uaRgJD8udDgD+VzD8xPzt7T2BhyS5vSZJahNYVXPc+wAnAhIgYl8/7H+Ay4J6IOBl4Ezg6b3sQOASYAiwFTqpgbZIkFVLFgjml9Hcg6mgeUEv/BHynUvVIkrQ28MpfkiQViMEsSVKBGMySJBWIwSxJUoEYzJIkFYjBLElSgRjMkiQViMEsSVKBGMySJBWIwSxJUoEYzJIkFYjBLElSgRjMkiQViMEsSVKBGMySJBWIwSxJUoEYzJIkFYjBLElSgRjMkiQViMEsSVKBGMySJBWIwSxJUoEYzJIkFYjBLElSgRjMkiQViMEsSVKBGMySJBWIwSxJUoEYzJIkFYjBLElSgRjMkiQViMEsSVKBGMySJBWIwSxJUoEYzJIkFYjBLElSgRjMkiQViMEsSVKBGMySJBWIwSxJUoEYzJIkFYjBLElSgRjMkiQViMEsSVKBGMySJBWIwSxJUoEYzJIkFYjBLElSgRjMkiQViMEsSVKBGMySJBWIwSxJUoEYzJIkFYjBLElSgRQqmCPioIh4OSKmRMQFzV2PJElNrTDBHBGtgGuBg4EdgMERsUPzViVJUtMqTDADuwNTUkqvpZQ+BO4CDm/mmiRJalJFCubNgWkl09PzeZIktRitm7uA1RURQ4Gh+eTiiHi5OeuRPrOGsykwp7nLkIoghkdjr7JbXQ1FCuYZwBYl013zeatIKd0I3NhURUktVUSMSSn1be46pJamSLuyRwPbRMRWEdEWOBYY2cw1SZLUpAozYk4pLY+I04CHgVbAr1NKE5u5LEmSmlSklJq7BkkFFBFD80NHkpqQwSxJUoEU6RizJEktnsEstUAR8fmIuCsipkbE2Ih4MCK2jYhlETEuIiZFxPURsU5E9I+IB2osf2tEHNlc9UufZYU5+UtS04iIAP4IjEgpHZvP6w1sBkxNKfWJiNbAE8DXgHnNVqzUAjlillqeLwEfpZSur5qRUnqJkivvpZSWA6OArZu+PKllM5illmcnYGx9HSJiPWAAMKFJKpJUzWCWVKpHRIwDngX+klJ6CKjroxt+pEOqAI8xSy3PRKCuE7emppT61Jg3F9ioxryN8TraUkU4YpZanieAdvkNYQCIiJ1Z9Vr1pV4FukTE9nnfbkBvYFylC5VaIkfMUguTUkoR8XXg6og4H3gfeAM4s47+H0TEN4HfRER74CPglJTSwqaqWWpJvPKXJEkF4q5sSZIKxGCWJKlADGZJkgrEYJYkqUAMZkmSCsRgliSpQAxmSZIKxGCWJKlA/j/TSit5r0KzdQAAAABJRU5ErkJggg==\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kIWlIBvkMLAS"
      },
      "source": [
        "Pipeline does not help improve latency on CPU."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "s6ZTYbyBB9F8"
      },
      "source": [
        "## 3. Inference time | ONNX Runtime"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6WuzVpniCACF"
      },
      "source": [
        "[ONNX Runtime](https://onnxruntime.ai/) helps **accelerate PyTorch and TensorFlow models in production, on CPU or GPU**. As an open source library built for performance and broad platform support, ONNX Runtime is used in products and services handling over 20 billion inferences each day. "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n9AcUibxJGXt"
      },
      "source": [
        "### 3.1 Old method | convert_graph_to_onnx.py"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "G6AD86PrI99o"
      },
      "source": [
        "You can use ONNX Runtime and Hugging Face Transformers together to improve the experience of training and deploying NLP models. Hugging Face has made it easy to inference Transformer models with ONNX Runtime with the [transformers/convert_graph_to_onnx.py](https://github.com/huggingface/transformers/blob/master/src/transformers/convert_graph_to_onnx.py) which generates a model that can be loaded by ONNX Runtime."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "691vn7sAGypy",
        "outputId": "cc40861f-323c-4cc1-ccd5-0d27128d72af"
      },
      "source": [
        "!python -m transformers.onnx --help"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "usage: Hugging Face ONNX Exporter tool [-h] -m MODEL\n",
            "                                       [--feature {causal-lm,causal-lm-with-past,default,default-with-past,masked-lm,seq2seq-lm,seq2seq-lm-with-past,sequence-classification,sequence-classification-with-past,token-classification}]\n",
            "                                       [--opset OPSET] [--atol ATOL]\n",
            "                                       output\n",
            "\n",
            "positional arguments:\n",
            "  output                Path indicating where to store generated ONNX model.\n",
            "\n",
            "optional arguments:\n",
            "  -h, --help            show this help message and exit\n",
            "  -m MODEL, --model MODEL\n",
            "                        Model's name of path on disk to load.\n",
            "  --feature {causal-lm,causal-lm-with-past,default,default-with-past,masked-lm,seq2seq-lm,seq2seq-lm-with-past,sequence-classification,sequence-classification-with-past,token-classification}\n",
            "                        Export the model with some additional feature.\n",
            "  --opset OPSET         ONNX opset version to export the model with (default\n",
            "                        12).\n",
            "  --atol ATOL           Absolute difference tolerence when validating the\n",
            "                        model.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jpByQiFAeOoY"
      },
      "source": [
        "````\n",
        "SUPPORTED_PIPELINES = [\n",
        "    \"feature-extraction\",\n",
        "    \"ner\",\n",
        "    \"sentiment-analysis\",\n",
        "    \"fill-mask\",\n",
        "    \"question-answering\",\n",
        "    \"text-generation\",\n",
        "    \"translation_en_to_fr\",\n",
        "    \"translation_en_to_de\",\n",
        "    \"translation_en_to_ro\",\n",
        "]\n",
        "````"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MIq7eMLLdBWf"
      },
      "source": [
        "Get the file convert_graph_to_onnx.py"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GrSHTpBILZPd",
        "outputId": "7aa809bd-cca1-45a5-9f08-d415fc808e7e"
      },
      "source": [
        "!wget https://raw.githubusercontent.com/huggingface/transformers/master/src/transformers/convert_graph_to_onnx.py"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2021-10-22 16:24:11--  https://raw.githubusercontent.com/huggingface/transformers/master/src/transformers/convert_graph_to_onnx.py\n",
            "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 185.199.108.133, 185.199.109.133, 185.199.110.133, ...\n",
            "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|185.199.108.133|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 18640 (18K) [text/plain]\n",
            "Saving to: ‘convert_graph_to_onnx.py’\n",
            "\n",
            "convert_graph_to_on 100%[===================>]  18.20K  --.-KB/s    in 0s      \n",
            "\n",
            "2021-10-22 16:24:11 (40.9 MB/s) - ‘convert_graph_to_onnx.py’ saved [18640/18640]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rtxn_TnPUqYZ"
      },
      "source": [
        "### 3.1.1 Tokenize the inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "371tF1SsYhwM"
      },
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True)"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oDusFXaeUqYa",
        "outputId": "6efc42f1-c5a3-4631-f534-7318636c6701"
      },
      "source": [
        "num=100\n",
        "\n",
        "total = 0\n",
        "for i in range(num):\n",
        "  start = perf_counter()\n",
        "  # WARNING!!!!!!! return_tensors=\"np\" and not return_tensors=\"pt\"\n",
        "  inputs = tokenizer(question, context, add_special_tokens=True, return_tensors=\"np\")\n",
        "  diff = perf_counter() - start\n",
        "  total += diff\n",
        "\n",
        "onnx_mean_tokenizer = round((total/num)*1000,2)\n",
        "print(f'average time: {onnx_mean_tokenizer} ms')"
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average time: 0.71 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "meVmR4E6L3va"
      },
      "source": [
        "### 3.1.2 Model on CPU"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ce7NwpoITBr3"
      },
      "source": [
        "#### Installation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "arWxHIgrJrqq"
      },
      "source": [
        "%%capture\n",
        "# onnxruntime cpu\n",
        "!pip install onnx\n",
        "!pip install onnxruntime"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "JyCazZPzMdFs",
        "outputId": "39ed6d8f-c681-42dc-aa6f-6089e5971e8b"
      },
      "source": [
        "import onnxruntime as ort\n",
        "ort.get_device()"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'CPU'"
            ]
          },
          "metadata": {},
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pfevyxkXdopX",
        "outputId": "758af8b3-6f5d-46b3-a1d4-1f669080a1d4"
      },
      "source": [
        "import onnxruntime\n",
        "print(\"onnxruntime:\",onnxruntime.__version__)"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "onnxruntime: 1.9.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q7JbUW_0dE53"
      },
      "source": [
        "#### Convert the transformer model to its quantized onnx version"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ASCjNxFpJosm",
        "outputId": "36b86409-34fe-4c81-b3ad-0289de4a29ee"
      },
      "source": [
        "model_checkpoint_onnx = 'onnx_cpu/' + model_checkpoint.replace('/','-') + '.onnx'\n",
        "\n",
        "!python convert_graph_to_onnx.py \\\n",
        "--pipeline question-answering \\\n",
        "--model {model_checkpoint} \\\n",
        "--tokenizer {model_checkpoint} \\\n",
        "--framework pt \\\n",
        "--opset 11 \\\n",
        "--check-loading \\\n",
        "--use-external-format \\\n",
        "--quantize \\\n",
        "{model_checkpoint_onnx}"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "====== Converting model to ONNX ======\n",
            "ONNX opset version set to: 11\n",
            "Loading pipeline (model: pierreguillou/bert-base-cased-squad-v1.1-portuguese, tokenizer: pierreguillou/bert-base-cased-squad-v1.1-portuguese)\n",
            "Creating folder /content/onnx_cpu\n",
            "Using framework PyTorch: 1.9.0+cu111\n",
            "Found input input_ids with shape: {0: 'batch', 1: 'sequence'}\n",
            "Found input token_type_ids with shape: {0: 'batch', 1: 'sequence'}\n",
            "Found input attention_mask with shape: {0: 'batch', 1: 'sequence'}\n",
            "Found output output_0 with shape: {0: 'batch', 1: 'sequence'}\n",
            "Found output output_1 with shape: {0: 'batch', 1: 'sequence'}\n",
            "Ensuring inputs are in correct order\n",
            "position_ids is not present in the generated input list.\n",
            "Generated inputs order: ['input_ids', 'attention_mask', 'token_type_ids']\n",
            "\n",
            "====== Optimizing ONNX model ======\n",
            "2021-10-22 16:24:34.644953871 [W:onnxruntime:, inference_session.cc:1419 Initialize] Serializing optimized model with Graph Optimization level greater than ORT_ENABLE_EXTENDED and the NchwcTransformer enabled. The generated model may contain hardware specific optimizations, and should only be used in the same environment the model was optimized in.\n",
            "Optimized model has been written at /content/onnx_cpu/pierreguillou-bert-base-cased-squad-v1.onnx: ✔\n",
            "/!\\ Optimized model contains hardware specific operators which might not be portable. /!\\\n",
            "As of onnxruntime 1.4.0, models larger than 2GB will fail to quantize due to protobuf constraint.\n",
            "This limitation will be removed in the next release of onnxruntime.\n",
            "WARNING:root:onnxruntime.quantization.quantize is deprecated.\n",
            "         Please use quantize_static for static quantization, quantize_dynamic for dynamic quantization.\n",
            "Warning: Unsupported operator LayerNormalization. No schema registered for this operator.\n",
            "Warning: Unsupported operator FusedMatMul. No schema registered for this operator.\n",
            "Warning: Unsupported operator LayerNormalization. No schema registered for this operator.\n",
            "Warning: Unsupported operator Gelu. No schema registered for this operator.\n",
            "Warning: Unsupported operator LayerNormalization. No schema registered for this operator.\n",
            "Warning: Unsupported operator FusedMatMul. No schema registered for this operator.\n",
            "Warning: Unsupported operator LayerNormalization. No schema registered for this operator.\n",
            "Warning: Unsupported operator Gelu. No schema registered for this operator.\n",
            "Warning: Unsupported operator LayerNormalization. No schema registered for this operator.\n",
            "Warning: Unsupported operator FusedMatMul. No schema registered for this operator.\n",
            "Warning: Unsupported operator LayerNormalization. No schema registered for this operator.\n",
            "Warning: Unsupported operator Gelu. No schema registered for this operator.\n",
            "Warning: Unsupported operator LayerNormalization. No schema registered for this operator.\n",
            "Warning: Unsupported operator FusedMatMul. No schema registered for this operator.\n",
            "Warning: Unsupported operator LayerNormalization. No schema registered for this operator.\n",
            "Warning: Unsupported operator Gelu. No schema registered for this operator.\n",
            "Warning: Unsupported operator LayerNormalization. No schema registered for this operator.\n",
            "Warning: Unsupported operator FusedMatMul. No schema registered for this operator.\n",
            "Warning: Unsupported operator LayerNormalization. No schema registered for this operator.\n",
            "Warning: Unsupported operator Gelu. No schema registered for this operator.\n",
            "Warning: Unsupported operator LayerNormalization. No schema registered for this operator.\n",
            "Warning: Unsupported operator FusedMatMul. No schema registered for this operator.\n",
            "Warning: Unsupported operator LayerNormalization. No schema registered for this operator.\n",
            "Warning: Unsupported operator Gelu. No schema registered for this operator.\n",
            "Warning: Unsupported operator LayerNormalization. No schema registered for this operator.\n",
            "Warning: Unsupported operator FusedMatMul. No schema registered for this operator.\n",
            "Warning: Unsupported operator LayerNormalization. No schema registered for this operator.\n",
            "Warning: Unsupported operator Gelu. No schema registered for this operator.\n",
            "Warning: Unsupported operator LayerNormalization. No schema registered for this operator.\n",
            "Warning: Unsupported operator FusedMatMul. No schema registered for this operator.\n",
            "Warning: Unsupported operator LayerNormalization. No schema registered for this operator.\n",
            "Warning: Unsupported operator Gelu. No schema registered for this operator.\n",
            "Warning: Unsupported operator LayerNormalization. No schema registered for this operator.\n",
            "Warning: Unsupported operator FusedMatMul. No schema registered for this operator.\n",
            "Warning: Unsupported operator LayerNormalization. No schema registered for this operator.\n",
            "Warning: Unsupported operator Gelu. No schema registered for this operator.\n",
            "Warning: Unsupported operator LayerNormalization. No schema registered for this operator.\n",
            "Warning: Unsupported operator FusedMatMul. No schema registered for this operator.\n",
            "Warning: Unsupported operator LayerNormalization. No schema registered for this operator.\n",
            "Warning: Unsupported operator Gelu. No schema registered for this operator.\n",
            "Warning: Unsupported operator LayerNormalization. No schema registered for this operator.\n",
            "Warning: Unsupported operator FusedMatMul. No schema registered for this operator.\n",
            "Warning: Unsupported operator LayerNormalization. No schema registered for this operator.\n",
            "Warning: Unsupported operator Gelu. No schema registered for this operator.\n",
            "Warning: Unsupported operator LayerNormalization. No schema registered for this operator.\n",
            "Warning: Unsupported operator FusedMatMul. No schema registered for this operator.\n",
            "Warning: Unsupported operator LayerNormalization. No schema registered for this operator.\n",
            "Warning: Unsupported operator Gelu. No schema registered for this operator.\n",
            "Warning: Unsupported operator LayerNormalization. No schema registered for this operator.\n",
            "Quantized model has been written at /content/onnx_cpu/pierreguillou-bert-base-cased-squad-v1-quantized.onnx: ✔\n",
            "\n",
            "====== Check exported ONNX model(s) ======\n",
            "Checking ONNX model loading from: /content/onnx_cpu/pierreguillou-bert-base-cased-squad-v1.1-portuguese.onnx ...\n",
            "Model /content/onnx_cpu/pierreguillou-bert-base-cased-squad-v1.1-portuguese.onnx correctly loaded: ✔\n",
            "Checking ONNX model loading from: /content/onnx_cpu/pierreguillou-bert-base-cased-squad-v1.onnx ...\n",
            "Model /content/onnx_cpu/pierreguillou-bert-base-cased-squad-v1.onnx correctly loaded: ✔\n",
            "Checking ONNX model loading from: /content/onnx_cpu/pierreguillou-bert-base-cased-squad-v1-quantized.onnx ...\n",
            "Model /content/onnx_cpu/pierreguillou-bert-base-cased-squad-v1-quantized.onnx correctly loaded: ✔\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DaUBCbBVRTLS"
      },
      "source": [
        "#### Import the onnx quantized version of the model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "evHBG4EbN99U"
      },
      "source": [
        "import onnxruntime as ort\n",
        "\n",
        "# copy/paste the path to the file xxx.quantized.onnx\n",
        "ort_session = ort.InferenceSession(\"/content/\" + model_checkpoint_onnx)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9jl869YbRNwD"
      },
      "source": [
        "#### Run the onnx model"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "anXCXVTAUIgv",
        "outputId": "803e7d8e-3b2a-45fe-c2a0-770afeb69d39"
      },
      "source": [
        "num = 100\n",
        "\n",
        "total = 0\n",
        "for i in range(num):\n",
        "  start = perf_counter()\n",
        "  outputs = ort_session.run(None, dict(inputs))\n",
        "  diff = perf_counter() - start\n",
        "  total += diff\n",
        "\n",
        "onnx_mean_time_cpu = round((total/num)*1000,2)\n",
        "print(f'average time: {onnx_mean_time_cpu} ms')"
      ],
      "execution_count": 35,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average time: 712.35 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4I9gMNPvVKD6"
      },
      "source": [
        "Now, we can evaluate the time to get the answer."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bUNtq4WaVV5I",
        "outputId": "457088db-a23d-4b71-aeb8-04f71334a157"
      },
      "source": [
        "num = 100\n",
        "\n",
        "total = 0\n",
        "for i in range(num):\n",
        "  start = perf_counter()\n",
        "  # code source: https://huggingface.co/transformers/master/task_summary.html#extractive-question-answering\n",
        "\n",
        "  answer_start_scores = outputs[0]\n",
        "  answer_end_scores = outputs[1]\n",
        "\n",
        "  # Get the most likely beginning of answer with the argmax of the score\n",
        "  answer_start = np.argmax(answer_start_scores)\n",
        "  # Get the most likely end of answer with the argmax of the score\n",
        "  answer_end = np.argmax(answer_end_scores) + 1\n",
        "\n",
        "  input_ids = inputs[\"input_ids\"].tolist()[0]\n",
        "  answer = tokenizer.convert_tokens_to_string(tokenizer.convert_ids_to_tokens(input_ids[answer_start:answer_end]))\n",
        "\n",
        "  diff = perf_counter() - start\n",
        "  total += diff\n",
        "  \n",
        "  # print(f\"Question: {question}\")\n",
        "  # print(f\"Answer: {answer}\")\n",
        "\n",
        "onnx_mean_time_cpu_answer = round((total/num)*1000,2)\n",
        "print(f'average time: {onnx_mean_time_cpu_answer} ms')"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average time: 0.06 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VQyCmfZUX5nI",
        "outputId": "7a36052d-f07f-4ea2-c147-9c086495a2dd"
      },
      "source": [
        "print(f\"Question: {question}\")\n",
        "print(f\"Answer: {answer}\")"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Question: Quando começou a pandemia de Covid-19 no mundo?\n",
            "Answer: 1 de dezembro de 2019\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQEOebWYVV5J"
      },
      "source": [
        "Then, we have the total time when the model is on the CPU:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UDRAppQ_VV5J",
        "outputId": "faef9365-5428-4d2e-8ce4-b33fb5c0ea69"
      },
      "source": [
        "onnx_total_cpu = round(onnx_mean_tokenizer + onnx_mean_time_cpu + onnx_mean_time_cpu_answer,2)\n",
        "print(f'time: {onnx_total_cpu} ms')"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "time: 713.12 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rDV-A-S_cxwR"
      },
      "source": [
        "### 3.1.4 Results with ONNX Runtime"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 112
        },
        "id": "UcXeFapAzs2I",
        "outputId": "c5b49551-b38b-47ae-b2f8-5e8a27309909"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "raw_data = {\n",
        "            'Latency on CPU (ms)': [mean_time_cpu, onnx_mean_time_cpu],\n",
        "            }\n",
        "\n",
        "df = pd.DataFrame(raw_data,\n",
        "                  index=pd.Index(['PyTorch (without pipeline)', 'ONNX Runtime']),\n",
        "                  columns=pd.Index(['Latency on CPU (ms)']))\n",
        "\n",
        "df"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Latency on CPU (ms)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>PyTorch (without pipeline)</th>\n",
              "      <td>866.69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ONNX Runtime</th>\n",
              "      <td>712.35</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            Latency on CPU (ms)\n",
              "PyTorch (without pipeline)               866.69\n",
              "ONNX Runtime                             712.35"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "8By6zvp_cxwR",
        "outputId": "83266fd4-150f-438b-b307-8e56fb8d49e5"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "labels = ['CPU']\n",
        "data = [mean_time_cpu, onnx_mean_time_cpu]\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "\n",
        "X = np.arange(1)\n",
        "ax.bar(X - 0.1, data[0], color = 'r', width = 0.2, label='PyTorch (without pipeline)')\n",
        "ax.bar(X + 0.1, data[1], color = 'g', width = 0.2, label='ONNX Runtime')\n",
        "\n",
        "# axes and title\n",
        "x = np.arange(len(labels))  # the label locations\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(labels)\n",
        "ax.set_ylabel('Latency (ms)')\n",
        "ax.set_title('Inference latency (CPU)')\n",
        "\n",
        "leg = ax.legend();"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "1WI18RL5cxwR"
      },
      "source": [
        "- ONNX Runtime helps improve latency on CPU (just a bit).\n",
        "- On CPU, using **ONNX Runtime** allows inferring up to **1.2 times faster** than with the PyTorch model (**632.58 ms** with ONNX Runtime)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qPQdX75lWG1C"
      },
      "source": [
        "### 3.2 New method | transformers.onnx"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_lBK1y0UFjSO"
      },
      "source": [
        "(source: [Configuration-based approach](https://huggingface.co/transformers/master/serialization.html#configuration-based-approach)) Transformers v4.9.0 introduces a new package: `transformers.onnx`. **This package allows converting checkpoints to an ONNX graph by leveraging configuration objects.** These configuration objects come ready made for a number of model architectures, and are made to be easily extendable to other architectures.\n",
        "\n",
        "Ready-made configurations include the following models:\n",
        "\n",
        "````\n",
        "ALBERT\n",
        "BART\n",
        "BERT\n",
        "DistilBERT\n",
        "GPT Neo\n",
        "LayoutLM\n",
        "Longformer\n",
        "mBART\n",
        "OpenAI GPT-2\n",
        "RoBERTa\n",
        "T5\n",
        "XLM-RoBERTa\n",
        "````"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LdKK7nYXWib8"
      },
      "source": [
        "Run `transformers.onnx` (or the conversion script located at [transformers/convert_graph_to_onnx.py](https://github.com/huggingface/transformers/blob/master/src/transformers/convert_graph_to_onnx.py)). This script takes a few arguments such as the model to be exported and the framework you want to export from (PyTorch or TensorFlow)."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8taFL-OHddE_"
      },
      "source": [
        "**WARNING**: which arguments to use?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mKf91Ju0Wib8"
      },
      "source": [
        "It will be exported under `onnx/pierreguillou-bert-base-cased-squad-v1.1-portuguese`."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-sH97kXWib8",
        "outputId": "162e5db4-d499-4b33-e709-03ad88c70138"
      },
      "source": [
        "%%time\n",
        "model_checkpoint_onnx = 'onnx/' + model_checkpoint.replace('/','-')\n",
        "\n",
        "!python -m transformers.onnx --model {model_checkpoint} {model_checkpoint_onnx}"
      ],
      "execution_count": null,
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Some weights of the model checkpoint at pierreguillou/bert-base-cased-squad-v1.1-portuguese were not used when initializing BertModel: ['qa_outputs.bias', 'qa_outputs.weight']\n",
            "- This IS expected if you are initializing BertModel from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
            "- This IS NOT expected if you are initializing BertModel from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
            "Some weights of BertModel were not initialized from the model checkpoint at pierreguillou/bert-base-cased-squad-v1.1-portuguese and are newly initialized: ['bert.pooler.dense.weight', 'bert.pooler.dense.bias']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n",
            "Using framework PyTorch: 1.9.0+cu111\n",
            "Overriding 1 configuration item(s)\n",
            "\t- use_cache -> False\n",
            "Validating ONNX model...\n",
            "\t-[✓] ONNX model outputs' name match reference model ({'last_hidden_state', 'pooler_output'}\n",
            "\t- Validating ONNX Model output \"last_hidden_state\":\n",
            "\t\t-[✓] (2, 8, 768) matches (2, 8, 768)\n",
            "\t\t-[✓] all values close (atol: 0.0001)\n",
            "\t- Validating ONNX Model output \"pooler_output\":\n",
            "\t\t-[✓] (2, 768) matches (2, 768)\n",
            "\t\t-[✓] all values close (atol: 0.0001)\n",
            "All good, model saved at: onnx/pierreguillou-bert-base-cased-squad-v1.1-portuguese/model.onnx\n",
            "CPU times: user 119 ms, sys: 143 ms, total: 262 ms\n",
            "Wall time: 16.8 s\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cKopthXBSXAP"
      },
      "source": [
        "The outputs can be obtained by taking a look at the ONNX configuration of each model. For example, for BERT:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-KOpz6RSIH1",
        "outputId": "f2735777-daa2-4ea4-f17c-5115f6e27120"
      },
      "source": [
        "from transformers.models.bert import BertOnnxConfig, BertConfig\n",
        "\n",
        "config = BertConfig()\n",
        "onnx_config = BertOnnxConfig(config)\n",
        "output_keys = list(onnx_config.outputs.keys())\n",
        "output_keys"
      ],
      "execution_count": null,
      "outputs": [
        {
          "data": {
            "text/plain": [
              "['last_hidden_state', 'pooler_output']"
            ]
          },
          "execution_count": 52,
          "metadata": {},
          "output_type": "execute_result"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rQvqPtLaY3tG"
      },
      "source": [
        "**WARNING**: these outputs do not allow to get an answer!!!!!"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SC7iQP-sdjpR"
      },
      "source": [
        "We can not continue. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0yk6QyZyKv4k"
      },
      "source": [
        "# import onnxruntime as ort\n",
        "# ort_session = ort.InferenceSession('onnx/pierreguillou-bert-base-cased-squad-v1.1-portuguese/model.onnx')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5K4w5U7u0nKI"
      },
      "source": [
        "## 4. Inference time | TorchScript"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TSA0tteRsiz1"
      },
      "source": [
        "source: https://huggingface.co/transformers/serialization.html#torchscript"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0cmuvCVLsovC"
      },
      "source": [
        "According to Pytorch’s documentation: “TorchScript is a way to create serializable and optimizable models from PyTorch code”. Pytorch’s two modules JIT and TRACE allow the developer to export their model to be re-used in other programs, such as efficiency-oriented C++ programs."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rhJM05N8svj1"
      },
      "source": [
        "Hugging Face provided an interface that allows the export of 🤗 Transformers models to TorchScript so that they can be reused in a different environment than a Pytorch-based python program. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Wt7_TL5P9ZM"
      },
      "source": [
        "from transformers import AutoTokenizer, AutoModelForQuestionAnswering\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint, use_fast=True, torchscript=True)\n",
        "model = AutoModelForQuestionAnswering.from_pretrained(model_checkpoint, torchscript=True)\n",
        "model.eval();"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hOG6K7tZqK2C"
      },
      "source": [
        "### 4.1 Tokenize the inputs"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OijtuOCLqK2D",
        "outputId": "21e81cf4-dfe5-4f20-fd9b-4c7340e3eb98"
      },
      "source": [
        "num=100\n",
        "\n",
        "total = 0\n",
        "for i in range(num):\n",
        "  start = perf_counter()\n",
        "  inputs = tokenizer(question, context, add_special_tokens=True, return_tensors=\"pt\")\n",
        "  diff = perf_counter() - start\n",
        "  total += diff\n",
        "\n",
        "torchscript_mean_tokenizer = round((total/num)*1000,2)\n",
        "print(f'average time: {torchscript_mean_tokenizer} ms')"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "average time: 0.75 ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0x_8BGWzQ8Yi"
      },
      "source": [
        "### 4.2 Model on CPU"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AhQwT81X8kk1",
        "outputId": "5e088704-a29e-45c2-b425-04a5b6753fd1"
      },
      "source": [
        "# put model and inputs to cpu\n",
        "model = model.to('cpu')\n",
        "inputs = inputs.to('cpu')\n",
        "\n",
        "# get mean time\n",
        "with torch.no_grad():\n",
        "  traced_model = torch.jit.trace(model, [inputs.input_ids,inputs.token_type_ids,inputs.attention_mask])\n",
        "  torchscript_mean_time_cpu = round(np.mean([timer(traced_model,inputs.input_ids,inputs.token_type_ids,inputs.attention_mask) for _ in range(100)]))\n",
        "print(f'{torchscript_mean_time_cpu}ms')"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "847ms\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WABOBcVIqyBx"
      },
      "source": [
        "### 4.3 Results with TorchScript"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 143
        },
        "id": "IhqwdJPGqyBy",
        "outputId": "11fa0e4d-95b2-4491-a327-7fdf4dd54db1"
      },
      "source": [
        "import pandas as pd\n",
        "\n",
        "raw_data = {\n",
        "            'Latency on CPU (ms)': [mean_time_cpu, onnx_mean_time_cpu, torchscript_mean_time_cpu],\n",
        "            }\n",
        "\n",
        "df = pd.DataFrame(raw_data,\n",
        "                  index=pd.Index(['PyTorch (without pipeline)', 'ONNX Runtime', 'TorchScript']),\n",
        "                  columns=pd.Index(['Latency on CPU (ms)']))\n",
        "\n",
        "df"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Latency on CPU (ms)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>PyTorch (without pipeline)</th>\n",
              "      <td>866.69</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>ONNX Runtime</th>\n",
              "      <td>712.35</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>TorchScript</th>\n",
              "      <td>847.00</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                            Latency on CPU (ms)\n",
              "PyTorch (without pipeline)               866.69\n",
              "ONNX Runtime                             712.35\n",
              "TorchScript                              847.00"
            ]
          },
          "metadata": {},
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 352
        },
        "id": "4z7trW6yqyBz",
        "outputId": "e39f8817-02df-4063-e894-03ec0fe1aa53"
      },
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "labels = ['CPU']\n",
        "data = [mean_time_cpu, onnx_mean_time_cpu, torchscript_mean_time_cpu]\n",
        "\n",
        "fig = plt.figure()\n",
        "ax = fig.add_axes([0,0,1,1])\n",
        "\n",
        "X = np.arange(1)\n",
        "ax.bar(X - 0.2, data[0], color = 'r', width = 0.2, label='PyTorch (without pipeline)')\n",
        "ax.bar(X, data[1], color = 'g', width = 0.2, label='ONNX Runtime')\n",
        "ax.bar(X + 0.2, data[2], color = 'b', width = 0.2, label='TorchScript')\n",
        "\n",
        "# axes and title\n",
        "x = np.arange(len(labels))  # the label locations\n",
        "ax.set_xticks(x)\n",
        "ax.set_xticklabels(labels)\n",
        "ax.set_ylabel('Latency (ms)')\n",
        "ax.set_title('Inference latency (CPU)')\n",
        "\n",
        "leg = ax.legend();"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8Emg1-pErnr2"
      },
      "source": [
        "- TorchScript does not help improve latency on CPU.\n",
        "- On CPU, it's better to use **ONNX Runtime**."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uMgo0Poja70v"
      },
      "source": [
        "# END"
      ]
    }
  ]
}